{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First We generate the outputs for the train, test and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "folder_path=\"generate_embeddings/dataset/all_sequences\"\n",
    "files=os.listdir(folder_path)\n",
    "\n",
    "all_accession_ids=[]\n",
    "all_sequences=[]\n",
    "for file in files:\n",
    "    file_path=os.path.join(folder_path,file)\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Read the contents of the file\n",
    "        file_contents = file.read()\n",
    "    splitted=file_contents.split(\"\\n\")\n",
    "    all_accession_ids.append(splitted[0].replace(\">\",\"\"))\n",
    "    all_sequences.append(splitted[1])\n",
    "\n",
    "all_accession_ids=all_accession_ids[:len(all_accession_ids)//2]\n",
    "all_sequences=all_sequences[:len(all_sequences)//2]\n",
    "\n",
    "train_id_file=\"generate_embeddings/dataset/TR_ids\"\n",
    "test1_id_file=\"generate_embeddings/dataset/TS1_ids\"\n",
    "test2_id_file=\"generate_embeddings/dataset/TS2_ids\"\n",
    "test3_id_file=\"generate_embeddings/dataset/TS3_ids\"\n",
    "valid_id_file=\"generate_embeddings/dataset/VL_ids\"\n",
    "\n",
    "train_ids=[]\n",
    "test1_ids=[]\n",
    "test2_ids=[]\n",
    "test3_ids=[]\n",
    "valid_ids=[]\n",
    "with open(train_id_file, \"r\") as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "splitted=file_contents.split(\"\\n\")\n",
    "for i in splitted:\n",
    "    if i!=\"\":\n",
    "        train_ids.append(i)\n",
    "\n",
    "with open(test1_id_file, \"r\") as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "splitted=file_contents.split(\"\\n\")\n",
    "for i in splitted:\n",
    "    if i!=\"\":\n",
    "        test1_ids.append(i)\n",
    "\n",
    "with open(test2_id_file, \"r\") as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "splitted=file_contents.split(\"\\n\")\n",
    "for i in splitted:\n",
    "    if i!=\"\":\n",
    "        test2_ids.append(i)\n",
    "\n",
    "with open(test3_id_file, \"r\") as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "splitted=file_contents.split(\"\\n\")\n",
    "for i in splitted:\n",
    "    if i!=\"\":\n",
    "        test3_ids.append(i)\n",
    "\n",
    "with open(valid_id_file, \"r\") as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()\n",
    "splitted=file_contents.split(\"\\n\")\n",
    "for i in splitted:\n",
    "    if i!=\"\":\n",
    "        valid_ids.append(i)\n",
    "\n",
    "\n",
    "\n",
    "train_sequences=[]\n",
    "test1_sequences=[]\n",
    "test2_sequences=[]\n",
    "test3_sequences=[]\n",
    "valid_sequences=[]\n",
    "\n",
    "for i in range(len(all_accession_ids)):\n",
    "    if all_accession_ids[i] in train_ids:\n",
    "        train_sequences.append(all_sequences[i])\n",
    "    elif all_accession_ids[i] in test1_ids:\n",
    "        test1_sequences.append(all_sequences[i])\n",
    "    elif all_accession_ids[i] in test2_ids:\n",
    "        test2_sequences.append(all_sequences[i])\n",
    "    elif all_accession_ids[i] in test3_ids:\n",
    "        test3_sequences.append(all_sequences[i])\n",
    "    elif all_accession_ids[i] in valid_ids:\n",
    "        valid_sequences.append(all_sequences[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=[]\n",
    "test1_labels=[]\n",
    "test2_labels=[]\n",
    "test3_labels=[]\n",
    "valid_labels=[]\n",
    "\n",
    "\n",
    "for i in range(len(all_accession_ids)):\n",
    "    if all_accession_ids[i] in train_ids:\n",
    "        filename=\"generate_embeddings/dataset/distance_contact_labels/\"+all_accession_ids[i]+\".true\"\n",
    "        data=np.loadtxt(filename)\n",
    "        train_labels.append(data)\n",
    "    elif all_accession_ids[i] in test1_ids:\n",
    "        filename=\"generate_embeddings/dataset/distance_contact_labels/\"+all_accession_ids[i]+\".true\"\n",
    "        data=np.loadtxt(filename)\n",
    "        test1_labels.append(data)\n",
    "    elif all_accession_ids[i] in test2_ids:\n",
    "        filename=\"generate_embeddings/dataset/distance_contact_labels/\"+all_accession_ids[i]+\".true\"\n",
    "        data=np.loadtxt(filename)\n",
    "        test2_labels.append(data)\n",
    "    elif all_accession_ids[i] in test3_ids:\n",
    "        filename=\"generate_embeddings/dataset/distance_contact_labels/\"+all_accession_ids[i]+\".true\"\n",
    "        data=np.loadtxt(filename)\n",
    "        test3_labels.append(data)\n",
    "    elif all_accession_ids[i] in valid_ids:\n",
    "        filename=\"generate_embeddings/dataset/distance_contact_labels/\"+all_accession_ids[i]+\".true\"\n",
    "        data=np.loadtxt(filename)\n",
    "        valid_labels.append(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "train_embeddings=pickle.load(open(\"generate_embeddings/embeddings/train_embeddings.pkl\",\"rb\"))\n",
    "test1_embeddings=pickle.load(open(\"generate_embeddings/embeddings/test1_embeddings.pkl\",\"rb\"))\n",
    "test2_embeddings=pickle.load(open(\"generate_embeddings/embeddings/test2_embeddings.pkl\",\"rb\"))\n",
    "test3_embeddings=pickle.load(open(\"generate_embeddings/embeddings/test3_embeddings.pkl\",\"rb\"))\n",
    "valid_embeddings=pickle.load(open(\"generate_embeddings/embeddings/valid_embeddings.pkl\",\"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([76, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the physiochemical properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rise</th>\n",
       "      <th>Roll</th>\n",
       "      <th>Shift</th>\n",
       "      <th>Slide</th>\n",
       "      <th>Tilt</th>\n",
       "      <th>Twist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bases</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>0.430303</td>\n",
       "      <td>0.403042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.695817</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AG</th>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.315589</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU</th>\n",
       "      <td>0.860606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.220532</td>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.548485</td>\n",
       "      <td>0.171103</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304183</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.315589</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.706061</td>\n",
       "      <td>0.277567</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.536122</td>\n",
       "      <td>0.494845</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GG</th>\n",
       "      <td>0.548485</td>\n",
       "      <td>0.171103</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GU</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.695817</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UC</th>\n",
       "      <td>0.706061</td>\n",
       "      <td>0.277567</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UG</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.220532</td>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UU</th>\n",
       "      <td>0.430303</td>\n",
       "      <td>0.403042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rise      Roll     Shift     Slide  Tilt     Twist\n",
       "Bases                                                        \n",
       "AA     0.430303  0.403042  1.000000  0.545455   0.4  0.833333\n",
       "AC     0.818182  0.695817  0.618557  1.000000   0.7  0.833333\n",
       "AG     0.257576  0.315589  0.762887  0.772727   0.3  0.791667\n",
       "AU     0.860606  1.000000  0.319588  0.863636   0.6  0.750000\n",
       "CA     0.045455  0.220532  0.360825  0.090909   0.1  0.291667\n",
       "CC     0.548485  0.171103  0.731959  0.545455   0.3  1.000000\n",
       "CG     0.000000  0.304183  0.371134  0.000000   0.0  0.333333\n",
       "CU     0.257576  0.315589  0.762887  0.772727   0.3  0.791667\n",
       "GA     0.706061  0.277567  0.618557  0.500000   0.4  0.833333\n",
       "GC     1.000000  0.536122  0.494845  0.500000   1.0  0.750000\n",
       "GG     0.548485  0.171103  0.731959  0.545455   0.3  1.000000\n",
       "GU     0.818182  0.695817  0.618557  1.000000   0.7  0.833333\n",
       "UA     0.000000  0.000000  0.000000  0.136364   0.0  0.000000\n",
       "UC     0.706061  0.277567  0.618557  0.500000   0.4  0.833333\n",
       "UG     0.045455  0.220532  0.360825  0.090909   0.1  0.291667\n",
       "UU     0.430303  0.403042  1.000000  0.545455   0.4  0.833333"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pcp_df = pd.read_excel(\"generate_embeddings/dataset/physiochemical_properties.xlsx\", index_col=0)\n",
    "pcp_df\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "pcp_df.loc[:, :] = scaler.fit_transform(pcp_df.values)\n",
    "pcp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_seq = train_sequences[0]\n",
    "dimars=[ a_seq[i:i+2] for i in range(len(a_seq) - 1) ]\n",
    "all_properties=[]\n",
    "for i in range(len(dimars)):\n",
    "    properties=[]\n",
    "    properties.append([pcp_df.loc[dimars[i]][\"Rise\"], pcp_df.loc[dimars[i]][\"Roll\"], pcp_df.loc[dimars[i]][\"Shift\"], pcp_df.loc[dimars[i]][\"Slide\"], pcp_df.loc[dimars[i]][\"Tilt\"], pcp_df.loc[dimars[i]][\"Twist\"]])\n",
    "\n",
    "    all_properties.append(properties)\n",
    "\n",
    "all_properties.append([-1,-1,-1,-1,-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n"
     ]
    }
   ],
   "source": [
    "# now generate physiochemical features\n",
    "all_train_properties=[]\n",
    "for i in range(len(train_sequences)):\n",
    "    print(i)\n",
    "    a_seq=train_sequences[i]\n",
    "    dimars=[ a_seq[i:i+2] for i in range(len(a_seq) - 1) ]\n",
    "    all_properties=[]\n",
    "    for i in range(len(dimars)):\n",
    "        if(dimars[i].find(\"X\")!=-1 or dimars[i].find(\"N\")!=-1):\n",
    "            all_properties.append([[-1,-1,-1,-1,-1,-1]])\n",
    "        else:\n",
    "            properties=[]\n",
    "            properties.append([pcp_df.loc[dimars[i]][\"Rise\"], pcp_df.loc[dimars[i]][\"Roll\"], pcp_df.loc[dimars[i]][\"Shift\"], pcp_df.loc[dimars[i]][\"Slide\"], pcp_df.loc[dimars[i]][\"Tilt\"], pcp_df.loc[dimars[i]][\"Twist\"]])\n",
    "            all_properties.append(properties)\n",
    "\n",
    "    all_properties.append([[-1,-1,-1,-1,-1,-1]])\n",
    "    all_train_properties.append(all_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n"
     ]
    }
   ],
   "source": [
    "all_x_train=[]\n",
    "all_y_train=[]\n",
    "\n",
    "\n",
    "for i in range(len(train_embeddings)):\n",
    "    print(i)\n",
    "    seq_input=train_embeddings[i]\n",
    "    seq_properties=all_train_properties[i]\n",
    "    seq_output=train_labels[i]\n",
    "    length=len(seq_input)\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "          \n",
    "            i_feat=seq_input[i].detach().numpy()\n",
    "            i_properties=np.array(seq_properties[i][0])\n",
    "            j_feat=seq_input[j].detach().numpy()\n",
    "            j_properties=np.array(seq_properties[j][0])\n",
    "\n",
    "            comb_feat=np.concatenate((i_feat,i_properties,j_feat,j_properties))\n",
    "            x.append(comb_feat)\n",
    "            y.append(seq_output[i][j])\n",
    "    all_x_train.append(x)\n",
    "    all_y_train.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mlen\u001b[39m(all_x_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_x_train' is not defined"
     ]
    }
   ],
   "source": [
    "len(all_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all_x_train and all_y_train as pickle files\n",
    "with open(\"generate_embeddings/dataset/final_datasets/all_x_train.pickle\", \"wb\") as file:\n",
    "    pickle.dump(all_x_train, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
